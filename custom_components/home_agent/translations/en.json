{
  "config": {
    "step": {
      "user": {
        "title": "Set up Home Agent",
        "description": "Configure your Home Agent with an OpenAI-compatible LLM endpoint.",
        "data": {
          "name": "Name",
          "llm_base_url": "LLM Base URL",
          "llm_api_key": "API Key",
          "llm_model": "Model Name",
          "llm_temperature": "Temperature",
          "llm_max_tokens": "Max Tokens"
        },
        "data_description": {
          "name": "Friendly name for this Home Agent instance",
          "llm_base_url": "OpenAI-compatible API endpoint (e.g., https://api.openai.com/v1)",
          "llm_api_key": "API key for authentication",
          "llm_model": "Model to use (e.g., gpt-4o-mini)",
          "llm_temperature": "Creativity level (0.0-2.0)",
          "llm_max_tokens": "Maximum tokens per response"
        }
      }
    },
    "error": {
      "cannot_connect": "Failed to connect to the LLM API",
      "invalid_auth": "Invalid API key",
      "invalid_url": "Invalid URL format",
      "unknown": "Unexpected error occurred"
    },
    "abort": {
      "already_configured": "This Home Agent instance is already configured"
    }
  },
  "options": {
    "step": {
      "init": {
        "title": "Configure Home Agent",
        "description": "Update your Home Agent configuration.",
        "menu_options": {
          "llm_settings": "LLM Settings",
          "context_settings": "Context Settings",
          "history_settings": "Conversation History",
          "prompt_settings": "System Prompt",
          "tool_settings": "Tool Configuration",
          "external_llm_settings": "External LLM",
          "debug_settings": "Debug Settings"
        }
      },
      "llm_settings": {
        "title": "LLM Settings",
        "description": "Configure the primary LLM connection and parameters.",
        "data": {
          "llm_base_url": "LLM Base URL",
          "llm_api_key": "API Key",
          "llm_model": "Model Name",
          "llm_temperature": "Temperature",
          "llm_max_tokens": "Max Tokens"
        },
        "data_description": {
          "llm_base_url": "OpenAI-compatible API endpoint (e.g., https://api.openai.com/v1 or http://localhost:11434/v1 for Ollama)",
          "llm_api_key": "API key for authentication",
          "llm_model": "Model to use (e.g., gpt-4o-mini, llama3.1)",
          "llm_temperature": "Controls randomness (0.0-2.0). Lower is more focused, higher is more creative.",
          "llm_max_tokens": "Maximum tokens per response"
        }
      },
      "context_settings": {
        "title": "Context Settings",
        "description": "Configure how entity context is provided to the LLM.",
        "data": {
          "context_mode": "Context Mode",
          "context_format": "Context Format",
          "direct_entities": "Entities to Include"
        },
        "data_description": {
          "context_mode": "Choose how to inject entity context",
          "context_format": "Format for entity data (JSON, Natural Language, or Hybrid)",
          "direct_entities": "Comma-separated list of entity IDs (e.g., sensor.temperature,light.*)"
        }
      },
      "history_settings": {
        "title": "Conversation History",
        "description": "Configure conversation history management.",
        "data": {
          "history_enabled": "Enable Conversation History",
          "history_max_messages": "Max Messages",
          "history_max_tokens": "Max Tokens"
        },
        "data_description": {
          "history_enabled": "Include previous conversation turns in LLM context",
          "history_max_messages": "Maximum number of conversation turns to retain",
          "history_max_tokens": "Token-based limit for history"
        }
      },
      "prompt_settings": {
        "title": "System Prompt",
        "description": "Configure the system prompt that guides the LLM's behavior.",
        "data": {
          "use_default_prompt": "Use Default System Prompt",
          "custom_prompt_additions": "Custom Prompt Additions"
        },
        "data_description": {
          "use_default_prompt": "Use Home Agent's built-in system prompt",
          "custom_prompt_additions": "Additional instructions to append to the system prompt"
        }
      },
      "tool_settings": {
        "title": "Tool Configuration",
        "description": "Configure tool execution limits and timeouts.",
        "data": {
          "tools_max_calls_per_turn": "Max Tool Calls Per Turn",
          "tools_timeout": "Tool Timeout (seconds)"
        },
        "data_description": {
          "tools_max_calls_per_turn": "Maximum number of tool executions per conversation turn",
          "tools_timeout": "Maximum execution time for each tool call"
        }
      },
      "external_llm_settings": {
        "title": "External LLM Configuration",
        "description": "Configure optional external LLM tool that the primary LLM can consult.",
        "data": {
          "external_llm_enabled": "Enable External LLM Tool",
          "external_llm_base_url": "External LLM Base URL",
          "external_llm_api_key": "External LLM API Key",
          "external_llm_model": "External LLM Model",
          "external_llm_temperature": "External LLM Temperature",
          "external_llm_max_tokens": "External LLM Max Tokens",
          "external_llm_tool_description": "Tool Description",
          "external_llm_auto_include_context": "Auto-include Context"
        },
        "data_description": {
          "external_llm_enabled": "Expose query_external_llm tool to primary LLM",
          "external_llm_base_url": "OpenAI-compatible API endpoint for external LLM",
          "external_llm_api_key": "API key for external LLM authentication",
          "external_llm_model": "External model name",
          "external_llm_temperature": "Temperature for external LLM responses",
          "external_llm_max_tokens": "Maximum tokens for external LLM responses",
          "external_llm_tool_description": "Description of when to use the external LLM",
          "external_llm_auto_include_context": "Automatically pass context to external LLM"
        }
      },
      "debug_settings": {
        "title": "Debug Settings",
        "description": "Configure debugging and logging options.",
        "data": {
          "debug_logging": "Enable Debug Logging"
        },
        "data_description": {
          "debug_logging": "Enable detailed logging for troubleshooting (may expose sensitive data)"
        }
      }
    }
  },
  "services": {
    "process": {
      "name": "Process message",
      "description": "Process a conversation message through the Home Agent",
      "fields": {
        "text": {
          "name": "Text",
          "description": "The user's message text to process"
        },
        "conversation_id": {
          "name": "Conversation ID",
          "description": "Optional conversation ID for history tracking"
        },
        "user_id": {
          "name": "User ID",
          "description": "Optional user ID for the conversation"
        },
        "entry_id": {
          "name": "Entry ID",
          "description": "Optional config entry ID to use"
        }
      }
    },
    "clear_history": {
      "name": "Clear history",
      "description": "Clear conversation history",
      "fields": {
        "conversation_id": {
          "name": "Conversation ID",
          "description": "Specific conversation to clear (omit to clear all)"
        },
        "entry_id": {
          "name": "Entry ID",
          "description": "Optional config entry ID to use"
        }
      }
    },
    "reload_context": {
      "name": "Reload context",
      "description": "Reload entity context",
      "fields": {
        "entry_id": {
          "name": "Entry ID",
          "description": "Optional config entry ID to use"
        }
      }
    },
    "execute_tool": {
      "name": "Execute tool",
      "description": "Manually execute a tool for testing",
      "fields": {
        "tool_name": {
          "name": "Tool name",
          "description": "The name of the tool to execute"
        },
        "parameters": {
          "name": "Parameters",
          "description": "Tool parameters as a JSON object"
        },
        "entry_id": {
          "name": "Entry ID",
          "description": "Optional config entry ID to use"
        }
      }
    }
  }
}
